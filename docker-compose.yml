# LiteLLM Proxy Configuration
# Single instance with Admin UI + API (free/open-source version)
#
# Usage: docker-compose up -d
#
# Endpoints:
#   - Admin UI: http://localhost:4000/ui
#   - API:      http://localhost:4000/v1/chat/completions
#
# Note: Separating Admin and API into different instances requires Enterprise license
#
# Version: main-v1.81.0-nightly (see VERSION file)

services:
  litellm:
    image: docker.litellm.ai/berriai/litellm:main-v1.81.0-nightly
    container_name: litellm
    ports:
      - "4000:4000"
    volumes:
      - ./litellm_config.yaml:/app/litellm_config.yaml
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY}
      - AZURE_API_BASE=${AZURE_API_BASE:-}
      - AZURE_API_KEY=${AZURE_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
    command: --config /app/litellm_config.yaml
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/health/liveliness"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - litellm-network

networks:
  litellm-network:
    driver: bridge
